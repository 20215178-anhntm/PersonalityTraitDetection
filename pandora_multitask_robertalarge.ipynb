{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14542419,"sourceType":"datasetVersion","datasetId":9288214}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cài thư viện cần (dựa trên code trong repo)\n!pip install transformers torch datasets accelerate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rNSrAqupcXs","outputId":"53d8c3a9-b170-400b-8c3d-0ae74e407e1b","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:08:18.314889Z","iopub.execute_input":"2026-01-19T08:08:18.315119Z","iopub.status.idle":"2026-01-19T08:08:23.271649Z","shell.execute_reply.started":"2026-01-19T08:08:18.315097Z","shell.execute_reply":"2026-01-19T08:08:23.270801Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip uninstall -y torch torchvision torchaudio\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:08:23.273686Z","iopub.execute_input":"2026-01-19T08:08:23.274013Z","iopub.status.idle":"2026-01-19T08:11:06.603343Z","shell.execute_reply.started":"2026-01-19T08:08:23.273984Z","shell.execute_reply":"2026-01-19T08:11:06.602576Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.8.0+cu126\nUninstalling torch-2.8.0+cu126:\n  Successfully uninstalled torch-2.8.0+cu126\nFound existing installation: torchvision 0.23.0+cu126\nUninstalling torchvision-0.23.0+cu126:\n  Successfully uninstalled torchvision-0.23.0+cu126\nFound existing installation: torchaudio 2.8.0+cu126\nUninstalling torchaudio-2.8.0+cu126:\n  Successfully uninstalled torchaudio-2.8.0+cu126\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==3.1.0 (from torch)\n  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nCollecting sympy==1.13.1 (from torch)\n  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: triton\n    Found existing installation: triton 3.4.0\n    Uninstalling triton-3.4.0:\n      Successfully uninstalled triton-3.4.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.3\n    Uninstalling sympy-1.13.3:\n      Successfully uninstalled sympy-1.13.3\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Kiểm tra GPU có sẵn không\nimport torch\nprint(\"GPU available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU name:\", torch.cuda.get_device_name(0))\n\n# Cài lại các thư viện cần (nếu chưa chạy trước đó)\n!pip install transformers torch datasets accelerate pandas scikit-learn tqdm\n\n# Nếu bạn đã ở trong thư mục repo thì bỏ dòng này\n%cd /content/Big-Five-personality-score-predictions_RoBERTa_and_BERT  # thay đổi nếu cần","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K17qnscIsfsF","outputId":"ec48da6f-713b-4eb8-d646-b6f89fe3e378","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:11:06.604833Z","iopub.execute_input":"2026-01-19T08:11:06.605520Z","iopub.status.idle":"2026-01-19T08:11:11.833820Z","shell.execute_reply.started":"2026-01-19T08:11:06.605487Z","shell.execute_reply":"2026-01-19T08:11:11.833079Z"}},"outputs":[{"name":"stdout","text":"GPU available: True\nGPU name: Tesla T4\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.5.1+cu121)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n[Errno 2] No such file or directory: '/content/Big-Five-personality-score-predictions_RoBERTa_and_BERT # thay đổi nếu cần'\n/kaggle/working\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Đường dẫn đến file trong folder WevMining (thay tên file nếu khác)\nfile_path = \"/kaggle/input/dataset/pandora_train.csv\"  # hoặc .parquet nếu là Parquet\n\nimport pandas as pd\n\n# Load file từ Drive\ndf = pd.read_csv(file_path)  # Nếu là Parquet: pd.read_parquet(file_path)\ndf = df.sample(frac=0.1, random_state=42)\n\n\nprint(\"Cột gốc trong file:\", df.columns.tolist())\n\n# Rename cột để khớp với code/repo mong đợi (body cho text)\ndf = df.rename(columns={\n    'text': 'body',\n    'A': 'agr',\n    'O': 'ope',\n    'C': 'con',\n    'E': 'ext',\n    'N': 'neu'\n})\n\n# Kiểm tra sau rename\nprint(\"\\nCột sau khi rename:\", df.columns.tolist())\nprint(\"\\nSample 3 dòng đầu:\")\nprint(df.head(3))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7NfbUYysmcd","outputId":"c090546d-733b-4cb8-cdd1-77bc8bfdb3f2","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:11:11.835314Z","iopub.execute_input":"2026-01-19T08:11:11.835918Z","iopub.status.idle":"2026-01-19T08:11:21.181423Z","shell.execute_reply.started":"2026-01-19T08:11:11.835886Z","shell.execute_reply":"2026-01-19T08:11:21.180563Z"}},"outputs":[{"name":"stdout","text":"Cột gốc trong file: ['O', 'C', 'E', 'A', 'N', 'ptype', 'text', '__index_level_0__']\n\nCột sau khi rename: ['ope', 'con', 'ext', 'agr', 'neu', 'ptype', 'body', '__index_level_0__']\n\nSample 3 dòng đầu:\n          ope   con   ext   agr   neu  ptype  \\\n258181    2.0  38.0  87.0  28.0   1.0      4   \n768973   81.0  80.0  30.0  24.0  75.0     25   \n1732080  29.0  40.0   6.0   7.0  98.0      1   \n\n                                                      body  __index_level_0__  \n258181   People who know they're close to zero balance ...            1386091  \n768973                        Aww You are most welcome. =]            2044374  \n1732080            Oh, didn't know it blocked her ult. TIL            1512060  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"","metadata":{"id":"ZhhQMvTktGPI"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport os\n\n# Load dataset đã rename\ndf[['ext', 'neu', 'agr', 'con', 'ope']] = df[['ext', 'neu', 'agr', 'con', 'ope']]/100\n\nprint(\"Dataset ready. Shape:\", df.shape)\n\n# Hiển thị nội dung của roberta_large_pandora.py để so sánh\nprint(\"\\n--- Nội dung của roberta_large_pandora.py ---\")\n!cat roberta_large_pandora.py\nprint(\"------------------------------------------\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ih-iQzdRtGoT","outputId":"c6dea28e-acc2-4597-ef80-d635c3cf2760","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:11:21.182617Z","iopub.execute_input":"2026-01-19T08:11:21.182886Z","iopub.status.idle":"2026-01-19T08:11:42.772043Z","shell.execute_reply.started":"2026-01-19T08:11:21.182863Z","shell.execute_reply":"2026-01-19T08:11:42.771329Z"}},"outputs":[{"name":"stderr","text":"2026-01-19 08:11:29.164042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768810289.380788      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768810289.447655      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768810290.024109      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768810290.024168      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768810290.024171      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768810290.024174      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Dataset ready. Shape: (192420, 8)\n\n--- Nội dung của roberta_large_pandora.py ---\ncat: roberta_large_pandora.py: No such file or directory\n------------------------------------------\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n\nmax_length = 128  # Tăng lên 128 để capture tốt hơn (repo gốc 64 quá ngắn cho Reddit comment)\n\ndef tokenize_text(text):\n    return tokenizer.encode_plus(\n        str(text),\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors=None\n    )\n\ndf['body'] = df['body'].apply(tokenize_text)\n\nprint(\"Tokenization completed. Sample:\", df['body'].iloc[0]['input_ids'][:10])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyJIZFIntMkg","outputId":"41bca704-3b73-48e4-e5a8-32956f0274c4","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:11:42.773523Z","iopub.execute_input":"2026-01-19T08:11:42.774489Z","iopub.status.idle":"2026-01-19T08:13:07.361932Z","shell.execute_reply.started":"2026-01-19T08:11:42.774457Z","shell.execute_reply":"2026-01-19T08:13:07.361036Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d77b8273b06b43c8a82810e848e1d9d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b644f5a552c2429ea528a0b29929fb15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00b0d8a04fe74e04a3366a8dab4396c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11eabf818564b22b992fec22f345716"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a8ca135dbb2422f8d7c9c28bfddfb43"}},"metadata":{}},{"name":"stdout","text":"Tokenization completed. Sample: [0, 4763, 54, 216, 51, 214, 593, 7, 4276, 2394]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Drop author nếu còn (dataset HF thường không có)\nif 'author' in df.columns:\n    df.drop(['author'], axis=1, inplace=True)\n\ndf_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\ndf_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42)\n\nprint(f\"Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fppS6uedtQSU","outputId":"a6e6fd5e-e22e-46c8-cf29-cc53f7766aeb","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:13:07.364474Z","iopub.execute_input":"2026-01-19T08:13:07.364783Z","iopub.status.idle":"2026-01-19T08:13:07.437867Z","shell.execute_reply.started":"2026-01-19T08:13:07.364755Z","shell.execute_reply":"2026-01-19T08:13:07.437280Z"}},"outputs":[{"name":"stdout","text":"Train: 107755 | Val: 26939 | Test: 57726\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class PersonalityDataset(Dataset):\n    def __init__(self, tweets, targets):\n        self.tweets = tweets\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.tweets)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': torch.tensor(self.tweets[idx]['input_ids'], dtype=torch.long),\n            'attention_mask': torch.tensor(self.tweets[idx]['attention_mask'], dtype=torch.long),\n            'targets': torch.tensor(self.targets[idx], dtype=torch.float)\n        }","metadata":{"id":"XEiWtsOItWBy","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:13:07.438689Z","iopub.execute_input":"2026-01-19T08:13:07.438992Z","iopub.status.idle":"2026-01-19T08:13:07.444877Z","shell.execute_reply.started":"2026-01-19T08:13:07.438958Z","shell.execute_reply":"2026-01-19T08:13:07.444229Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# batch_size = 8  # Giảm nếu Colab T4 hết VRAM (8-16 OK cho roberta-large)\n\n# train_dataset = PersonalityDataset(df_train['body'].tolist(), df_train[['ext', 'neu', 'agr', 'con', 'ope']].values)\n# val_dataset = PersonalityDataset(df_val['body'].tolist(), df_val[['ext', 'neu', 'agr', 'con', 'ope']].values)\n# test_dataset = PersonalityDataset(df_test['body'].tolist(), df_test[['ext', 'neu', 'agr', 'con', 'ope']].values)\n\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\nbatch_size = 6           # Giảm xuống để tránh OOM với roberta-large\n\n# Chỉ lấy cột 'ope' (Openness)\ntrain_dataset = PersonalityDataset(\n    df_train['body'].tolist(),\n    df_train[['ope']].values          # ← chỉ 1 cột thay vì 5\n)\n\nval_dataset = PersonalityDataset(\n    df_val['body'].tolist(),\n    df_val[['ope']].values\n)\n\ntest_dataset = PersonalityDataset(\n    df_test['body'].tolist(),\n    df_test[['ope']].values\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n\nprint(f\"Dataset chỉ cho Openness (O) đã sẵn sàng. Train samples: {len(train_dataset)}\")","metadata":{"id":"UJJXv9rOtaqM","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:13:07.445699Z","iopub.execute_input":"2026-01-19T08:13:07.446007Z","iopub.status.idle":"2026-01-19T08:13:07.472745Z","shell.execute_reply.started":"2026-01-19T08:13:07.445980Z","shell.execute_reply":"2026-01-19T08:13:07.472174Z"}},"outputs":[{"name":"stdout","text":"Dataset chỉ cho Openness (O) đã sẵn sàng. Train samples: 107755\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class RoBERTaForPersonalityTraits(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained('roberta-large')\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(1024, 1)  # 5 traits\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.pooler_output\n        output = self.dropout(pooled)\n        return self.linear(output)\n\nmodel = RoBERTaForPersonalityTraits()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.MSELoss()\n\nprint(\"Model loaded on:\", device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HEGCFVBtfno","outputId":"cf12f791-9f80-4dc8-ee75-bffc277b01c3","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:13:07.473718Z","iopub.execute_input":"2026-01-19T08:13:07.474154Z","iopub.status.idle":"2026-01-19T08:13:12.990085Z","shell.execute_reply.started":"2026-01-19T08:13:07.474128Z","shell.execute_reply":"2026-01-19T08:13:12.989074Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8018e8b64fcc41c8a01967a8a9315a15"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded on: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from transformers import RobertaModel\n\nclass RoBERTaForOpenness(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained('roberta-large')\n        self.dropout = torch.nn.Dropout(0.35)\n        self.linear  = torch.nn.Linear(1024, 1)          # Chỉ 1 output cho Openness\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.pooler_output\n        output = self.dropout(pooled)\n        return self.linear(output).squeeze(-1)           # Trả về scalar (batch_size,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:18:27.584098Z","iopub.execute_input":"2026-01-19T08:18:27.584480Z","iopub.status.idle":"2026-01-19T08:18:27.591380Z","shell.execute_reply.started":"2026-01-19T08:18:27.584452Z","shell.execute_reply":"2026-01-19T08:18:27.590608Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# epochs =20   # Bắt đầu với 3 để test, sau tăng\n# patience = 3\n# best_val_loss = float('inf')\n# patience_counter = 0\n# accumulation_steps = 4  # Gradient accumulation để tiết kiệm VRAM\n\n# log_file = 'roberta_large_results.txt'\n\n# with open(log_file, 'w') as f:\n#     f.write(\"Training started\\n\")\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_loss = 0\n#         step = 0\n\n#         train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/Training\")\n#         for i, batch in enumerate(train_bar):\n#             if i % accumulation_steps == 0:\n#                 optimizer.zero_grad()\n\n#             input_ids = batch['input_ids'].to(device)\n#             attention_mask = batch['attention_mask'].to(device)\n#             targets = batch['targets'].to(device)\n\n#             outputs = model(input_ids, attention_mask)\n#             loss = loss_fn(outputs, targets)\n\n#             loss = loss / accumulation_steps\n#             loss.backward()\n\n#             if (i + 1) % accumulation_steps == 0 or i + 1 == len(train_loader):\n#                 optimizer.step()\n#                 optimizer.zero_grad()\n\n#             total_loss += loss.item() * accumulation_steps\n#             step += 1\n\n#             train_bar.set_postfix({'loss': total_loss / step})\n\n#             # Checkpoint\n#             if step % 1000 == 0:\n#                 torch.save(model.state_dict(), f'checkpoint_step_{step}.pth')\n\n#         avg_train_loss = total_loss / step\n#         f.write(f\"Epoch {epoch+1}: Train Loss {avg_train_loss}\\n\")\n\n#         # Validation\n#         model.eval()\n#         val_loss = 0\n#         preds, trues = [], []\n#         with torch.no_grad():\n#             for batch in tqdm(val_loader, desc=\"Validation\"):\n#                 input_ids = batch['input_ids'].to(device)\n#                 attention_mask = batch['attention_mask'].to(device)\n#                 targets = batch['targets'].to(device)\n\n#                 outputs = model(input_ids, attention_mask)\n#                 val_loss += loss_fn(outputs, targets).item()\n\n#                 preds.append(outputs.cpu().numpy())\n#                 trues.append(targets.cpu().numpy())\n\n#         avg_val_loss = val_loss / len(val_loader)\n#         f.write(f\"Val Loss: {avg_val_loss}\\n\")\n\n#         if avg_val_loss < best_val_loss:\n#             best_val_loss = avg_val_loss\n#             patience_counter = 0\n#             torch.save(model.state_dict(), 'best_model.pth')\n#         else:\n#             patience_counter += 1\n#             if patience_counter >= patience:\n#                 f.write(\"Early stopping\\n\")\n#                 break\n\n#     torch.save(model.state_dict(), 'final_model.pth')\n#     f.write(\"Training done\\n\")\n\nmodel = RoBERTaForOpenness()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=6e-6)   # lr nhỏ hơn tí cho an toàn\nloss_fn = torch.nn.MSELoss()\n\nepochs = 15\npatience = 4\nbest_val_loss = float('inf')\npatience_counter = 0\naccumulation_steps = 8\n\nlog_file = 'roberta_large_openness_only.txt'\n\nwith open(log_file, 'w') as f:\n    f.write(\"Training chỉ cho Openness (O)\\n\")\n    f.write(\"Started\\n\\n\")\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        step = 0\n\n        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n        for i, batch in enumerate(train_bar):\n            if i % accumulation_steps == 0:\n                optimizer.zero_grad()\n\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device).squeeze(-1)   # ← squeeze rất quan trọng!\n\n            outputs = model(input_ids, attention_mask)\n            loss = loss_fn(outputs, targets)\n\n            loss = loss / accumulation_steps\n            loss.backward()\n\n            if (i + 1) % accumulation_steps == 0 or i + 1 == len(train_loader):\n                optimizer.step()\n                optimizer.zero_grad()\n\n            total_loss += loss.item() * accumulation_steps\n            step += 1\n            train_bar.set_postfix({'loss': f\"{total_loss / step:.5f}\"})\n\n        avg_train_loss = total_loss / step\n        f.write(f\"Epoch {epoch+1}: Train Loss {avg_train_loss:.6f}\\n\")\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            val_bar = tqdm(val_loader, desc=\"Validation\")\n            for batch in val_bar:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                targets = batch['targets'].to(device).squeeze(-1)\n\n                outputs = model(input_ids, attention_mask)\n                val_loss += loss_fn(outputs, targets).item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        f.write(f\"Val Loss: {avg_val_loss:.6f}\\n\")\n\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), 'best_model_openness.pth')\n            f.write(\"→ Saved best model\\n\")\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                f.write(\"Early stopping\\n\")\n                break\n\n    torch.save(model.state_dict(), 'final_model_openness.pth')\n    f.write(\"Training done\\n\")\n\nprint(\"Training cho Openness hoàn tất.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5hCJWZUYtg6N","outputId":"84419a3b-ca5d-4e9d-f44c-f251586a7ea8","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T08:18:31.346215Z","iopub.execute_input":"2026-01-19T08:18:31.346512Z","iopub.status.idle":"2026-01-19T19:34:15.374968Z","shell.execute_reply.started":"2026-01-19T08:18:31.346488Z","shell.execute_reply":"2026-01-19T19:34:15.373439Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1: 100%|██████████| 17960/17960 [2:26:47<00:00,  2.04it/s, loss=0.12310]  \nValidation: 100%|██████████| 4490/4490 [12:21<00:00,  6.05it/s]\nEpoch 2: 100%|██████████| 17960/17960 [2:26:53<00:00,  2.04it/s, loss=0.10479]  \nValidation: 100%|██████████| 4490/4490 [12:22<00:00,  6.04it/s]\nEpoch 3: 100%|██████████| 17960/17960 [2:26:49<00:00,  2.04it/s, loss=0.10014]  \nValidation: 100%|██████████| 4490/4490 [12:22<00:00,  6.05it/s]\nEpoch 4: 100%|██████████| 17960/17960 [2:26:44<00:00,  2.04it/s, loss=0.09515]  \nValidation: 100%|██████████| 4490/4490 [12:22<00:00,  6.04it/s]\nEpoch 5:  26%|██▋       | 4750/17960 [38:50<1:48:00,  2.04it/s, loss=0.08905]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2760242609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mtrain_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{total_loss / step:.5f}\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# Load model tốt nhất\nmodel.load_state_dict(torch.load('best_model_openness.pth'))\nmodel.eval()\n\ntest_loss = 0\nall_preds = []\nall_trues = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Test Openness\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device).squeeze(-1)\n\n        outputs = model(input_ids, attention_mask)\n        test_loss += loss_fn(outputs, targets).item()\n\n        all_preds.extend(outputs.cpu().numpy())\n        all_trues.extend(targets.cpu().numpy())\n\nmse = mean_squared_error(all_trues, all_preds)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(all_trues, all_preds)\nr2 = r2_score(all_trues, all_preds)\n\nprint(\"\\nKết quả trên test set - Openness (O):\")\nprint(f\"MSE:  {mse:.5f}\")\nprint(f\"RMSE: {rmse:.5f}\")\nprint(f\"MAE:  {mae:.5f}\")\nprint(f\"R²:   {r2:.5f}\")","metadata":{"id":"uFQL8mtutjIW","trusted":true,"execution":{"iopub.status.busy":"2026-01-19T19:35:02.080322Z","iopub.execute_input":"2026-01-19T19:35:02.080666Z","iopub.status.idle":"2026-01-19T20:01:38.498039Z","shell.execute_reply.started":"2026-01-19T19:35:02.080633Z","shell.execute_reply":"2026-01-19T20:01:38.497238Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/3628600644.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_model_openness.pth'))\nTest Openness: 100%|██████████| 9621/9621 [26:35<00:00,  6.03it/s]","output_type":"stream"},{"name":"stdout","text":"\nKết quả trên test set - Openness (O):\nMSE:  0.09076\nRMSE: 0.30126\nMAE:  0.26226\nR²:   0.06866\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15}]}