{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14538200,"sourceType":"datasetVersion","datasetId":9285545},{"sourceId":14538366,"sourceType":"datasetVersion","datasetId":9285683}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cài thư viện cần (dựa trên code trong repo)\n!pip install transformers torch datasets accelerate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rNSrAqupcXs","outputId":"53d8c3a9-b170-400b-8c3d-0ae74e407e1b","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T10:58:52.754828Z","iopub.execute_input":"2026-01-26T10:58:52.755439Z","iopub.status.idle":"2026-01-26T10:58:57.125945Z","shell.execute_reply.started":"2026-01-26T10:58:52.755412Z","shell.execute_reply":"2026-01-26T10:58:57.125295Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Kiểm tra GPU có sẵn không\nimport torch\nprint(\"GPU available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU name:\", torch.cuda.get_device_name(0))\n\n# Cài lại các thư viện cần (nếu chưa chạy trước đó)\n!pip install transformers torch datasets accelerate pandas scikit-learn tqdm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K17qnscIsfsF","outputId":"ec48da6f-713b-4eb8-d646-b6f89fe3e378","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T10:58:57.127505Z","iopub.execute_input":"2026-01-26T10:58:57.127758Z","iopub.status.idle":"2026-01-26T10:59:04.254597Z","shell.execute_reply.started":"2026-01-26T10:58:57.127731Z","shell.execute_reply":"2026-01-26T10:59:04.253592Z"}},"outputs":[{"name":"stdout","text":"GPU available: True\nGPU name: Tesla P100-PCIE-16GB\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Đường dẫn đến file trong folder WevMining (thay tên file nếu khác)\nfile_path = \"/kaggle/input/dataset/dataset (1).csv\"  # hoặc .parquet nếu là Parquet\n\nimport pandas as pd\nimport re\n\n# Load file\ndf = pd.read_csv(file_path)\n\nprint(\"Cột gốc trong file:\", df.columns.tolist())\n\n# Rename cột\ndf = df.rename(columns={\n    'text': 'body',\n    'A': 'agr',\n    'O': 'ope',\n    'C': 'con',\n    'E': 'ext',\n    'N': 'neu'\n})\n\n# LIGHT CLEAN - chỉ xóa URL và normalize space, giữ emoji, punctuation, caps\ndef light_clean(text):\n    if not isinstance(text, str):\n        text = str(text)\n    # Thay URL bằng placeholder (RoBERTa-large hiểu tốt [URL])\n    text = re.sub(r'http\\S+|www\\S+', '[URL]', text)\n    # Normalize space, loại bỏ khoảng trắng thừa\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndf['body'] = df['body'].apply(light_clean)\n\n# Sample nhỏ để test nhanh (tăng lên 0.1 hoặc full khi ổn)\ndf = df.sample(frac=0.1, random_state=42)  # ~34k mẫu\n\n# Normalize labels về 0-1\ndf[['ext', 'neu', 'agr', 'con', 'ope']] = df[['ext', 'neu', 'agr', 'con', 'ope']]/100\n\nprint(\"\\nCột sau khi rename & light clean:\", df.columns.tolist())\nprint(\"\\nSample 3 dòng đầu (giữ nguyên emoji/punctuation):\")\nprint(df.head(3))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7NfbUYysmcd","outputId":"c090546d-733b-4cb8-cdd1-77bc8bfdb3f2","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T10:59:04.255935Z","iopub.execute_input":"2026-01-26T10:59:04.256493Z","iopub.status.idle":"2026-01-26T10:59:43.054112Z","shell.execute_reply.started":"2026-01-26T10:59:04.256463Z","shell.execute_reply":"2026-01-26T10:59:43.053411Z"}},"outputs":[{"name":"stdout","text":"Cột gốc trong file: ['ope', 'con', 'ext', 'agr', 'neu', 'ptype', 'body', '__index_level_0__']\n\nCột sau khi rename & light clean: ['ope', 'con', 'ext', 'agr', 'neu', 'ptype', 'body', '__index_level_0__']\n\nSample 3 dòng đầu (giữ nguyên emoji/punctuation):\n          ope   con   ext   agr   neu  ptype  \\\n258181   0.02  0.38  0.87  0.28  0.01      4   \n768973   0.81  0.80  0.30  0.24  0.75     25   \n1732080  0.29  0.40  0.06  0.07  0.98      1   \n\n                                                      body  __index_level_0__  \n258181   People who know they're close to zero balance ...            1386091  \n768973                        Aww You are most welcome. =]            2044374  \n1732080            Oh, didn't know it blocked her ult. TIL            1512060  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"","metadata":{"id":"ZhhQMvTktGPI"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport os\ntokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n\n# max_length hợp lý cho RoBERTa-large\nmax_length = 96\n\ndef tokenize_text(text):\n    return tokenizer.encode_plus(\n        text,\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors=None\n    )\n\ndf['body'] = df['body'].apply(tokenize_text)\n\nprint(\"Tokenization hoàn tất. Shape:\", df.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ih-iQzdRtGoT","outputId":"c6dea28e-acc2-4597-ef80-d635c3cf2760","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T10:59:43.055232Z","iopub.execute_input":"2026-01-26T10:59:43.055887Z","iopub.status.idle":"2026-01-26T11:01:29.612469Z","shell.execute_reply.started":"2026-01-26T10:59:43.055862Z","shell.execute_reply":"2026-01-26T11:01:29.611654Z"}},"outputs":[{"name":"stderr","text":"2026-01-26 10:59:53.567729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769425193.758682      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769425193.813588      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769425194.265248      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769425194.265304      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769425194.265307      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769425194.265309      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6dcb21bc6ef4df2a22354c768720294"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db7dc7f8cb948b784db176dbc581ea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5ef0088a5614299a718fe0e1767a8e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e0e4db251fa4366985a1a74267b3546"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197b298d8c694a49bb59f41e07b5fa51"}},"metadata":{}},{"name":"stdout","text":"Tokenization hoàn tất. Shape: (192420, 8)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Split train/val/test\ndf_train, df_temp = train_test_split(df, test_size=0.3, random_state=42)\ndf_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n\n# Custom Dataset\nclass PersonalityDataset(Dataset):\n    def __init__(self, tokenized_texts, labels):\n        self.tokenized_texts = tokenized_texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = self.tokenized_texts[idx]\n        return {\n            'input_ids': torch.tensor(item['input_ids'], dtype=torch.long),\n            'attention_mask': torch.tensor(item['attention_mask'], dtype=torch.long),\n            'targets': torch.tensor(self.labels[idx], dtype=torch.float)\n        }\n\n# Tham số batch\nbatch_size = 16\naccumulation_steps = 4\n\ntrain_dataset = PersonalityDataset(df_train['body'].tolist(), df_train[['ext', 'neu', 'agr', 'con', 'ope']].values)\nval_dataset   = PersonalityDataset(df_val['body'].tolist(),   df_val[['ext', 'neu', 'agr', 'con', 'ope']].values)\ntest_dataset  = PersonalityDataset(df_test['body'].tolist(),  df_test[['ext', 'neu', 'agr', 'con', 'ope']].values)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)\n\nprint(f\"Dataset sizes → Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyJIZFIntMkg","outputId":"41bca704-3b73-48e4-e5a8-32956f0274c4","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:01:29.616248Z","iopub.execute_input":"2026-01-26T11:01:29.616943Z","iopub.status.idle":"2026-01-26T11:01:29.687782Z","shell.execute_reply.started":"2026-01-26T11:01:29.616917Z","shell.execute_reply":"2026-01-26T11:01:29.686987Z"}},"outputs":[{"name":"stdout","text":"Dataset sizes → Train: 134694 | Val: 28863 | Test: 28863\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import RobertaModel, get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nimport torch\n\nclass RoBERTaForPersonalityTraits(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained('roberta-large')\n       \n        # Freeze bottom layers\n        for param in self.roberta.embeddings.parameters():\n            param.requires_grad = False\n        for i in range(12):\n            for param in self.roberta.encoder.layer[i].parameters():\n                param.requires_grad = False\n       \n        self.dropout = torch.nn.Dropout(0.1)\n        self.head = torch.nn.Sequential(\n            torch.nn.Linear(1024, 512),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.1),\n            torch.nn.Linear(512, 5)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pooled = outputs.pooler_output\n        output = self.dropout(pooled)\n        return self.head(output)\n\nmodel = RoBERTaForPersonalityTraits()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\noptimizer = AdamW(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=1e-5,\n    weight_decay=0.01\n)\n\nloss_fn = torch.nn.MSELoss()\n\n# Thêm scheduler\nepochs = 12  # Đồng bộ với Cell 7\ntotal_steps = len(train_loader) * epochs\nwarmup_steps = int(0.1 * total_steps)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps\n)\n\nprint(\"Model loaded. Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\nprint(f\"Scheduler ready → Total steps: {total_steps:,} | Warmup: {warmup_steps:,}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fppS6uedtQSU","outputId":"a6e6fd5e-e22e-46c8-cf29-cc53f7766aeb","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:01:29.688835Z","iopub.execute_input":"2026-01-26T11:01:29.689354Z","iopub.status.idle":"2026-01-26T11:01:34.985331Z","shell.execute_reply.started":"2026-01-26T11:01:29.689320Z","shell.execute_reply":"2026-01-26T11:01:34.984460Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ed04b587a3d44f8b1614ca0c9f11f13"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded. Trainable params: 152731653\nScheduler ready → Total steps: 101,028 | Warmup: 10,102\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ────────────────────────────────────────────────────────────────\n# Cell 7: Training Loop với Mixed Precision (FP16) + Early Stopping\n# ────────────────────────────────────────────────────────────────\n\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\nimport torch\n\n# Tham số training\nepochs = 12               # Số epochs (có thể tăng nếu cần)\npatience = 5              # Số epochs chờ nếu val loss không cải thiện\nbest_val_loss = float('inf')\npatience_counter = 0\n\nscaler = GradScaler()     # Mixed precision scaler\n\nprint(f\"Bắt đầu training với {epochs} epochs, batch size hiệu quả = {batch_size * accumulation_steps}\")\n\nfor epoch in range(epochs):\n    model.train()\n    total_train_loss = 0\n    optimizer.zero_grad()\n    \n    loop = tqdm(train_loader, leave=True, desc=f\"Epoch {epoch+1}/{epochs}\")\n    for i, batch in enumerate(loop):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device)\n        \n        with autocast():\n            outputs = model(input_ids, attention_mask)\n            loss = loss_fn(outputs, targets) / accumulation_steps\n        \n        scaler.scale(loss).backward()\n        \n        if (i + 1) % accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            # Nếu bạn đã thêm scheduler ở Cell 6, gọi ở đây:\n            scheduler.step()   # Bỏ comment nếu có scheduler\n            \n        total_train_loss += loss.item() * accumulation_steps\n        \n        # Cập nhật progress bar\n        loop.set_postfix({'batch_loss': loss.item() * accumulation_steps})\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    \n    # ────────────────────────────────────────────────────────────────\n    # Validation\n    # ────────────────────────────────────────────────────────────────\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n            \n            with autocast():\n                outputs = model(input_ids, attention_mask)\n                loss = loss_fn(outputs, targets)\n            \n            total_val_loss += loss.item()\n    \n    avg_val_loss = total_val_loss / len(val_loader)\n    print(f\"Epoch {epoch+1}/{epochs} → Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n    \n    # Early stopping & save best model\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), 'best_roberta.pth')\n        print(\"→ Saved best model (val loss improved)\")\n    else:\n        patience_counter += 1\n        print(f\"Val loss không cải thiện ({patience_counter}/{patience})\")\n        if patience_counter >= patience:\n            print(\"Early stopping triggered!\")\n            break\n\nprint(\"\\nTraining hoàn tất.\")\nprint(f\"Best validation loss: {best_val_loss:.4f}\")","metadata":{"id":"XEiWtsOItWBy","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:01:34.986622Z","iopub.execute_input":"2026-01-26T11:01:34.986949Z","iopub.status.idle":"2026-01-26T19:01:52.753606Z","shell.execute_reply.started":"2026-01-26T11:01:34.986915Z","shell.execute_reply":"2026-01-26T19:01:52.752454Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/3610151879.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()     # Mixed precision scaler\n","output_type":"stream"},{"name":"stdout","text":"Bắt đầu training với 12 epochs, batch size hiệu quả = 64\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/12:   0%|          | 0/8419 [00:00<?, ?it/s]/tmp/ipykernel_55/3610151879.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 1/12: 100%|██████████| 8419/8419 [42:43<00:00,  3.28it/s, batch_loss=0.081] \n/tmp/ipykernel_55/3610151879.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/12 → Train Loss: 0.1194 | Val Loss: 0.0878\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/12: 100%|██████████| 8419/8419 [42:38<00:00,  3.29it/s, batch_loss=0.112] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/12 → Train Loss: 0.0877 | Val Loss: 0.0843\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/12: 100%|██████████| 8419/8419 [42:38<00:00,  3.29it/s, batch_loss=0.11]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/12 → Train Loss: 0.0849 | Val Loss: 0.0824\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/12: 100%|██████████| 8419/8419 [42:27<00:00,  3.31it/s, batch_loss=0.0785]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/12 → Train Loss: 0.0823 | Val Loss: 0.0810\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/12: 100%|██████████| 8419/8419 [42:33<00:00,  3.30it/s, batch_loss=0.0755]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/12 → Train Loss: 0.0797 | Val Loss: 0.0806\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/12: 100%|██████████| 8419/8419 [42:34<00:00,  3.30it/s, batch_loss=0.121] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/12 → Train Loss: 0.0766 | Val Loss: 0.0797\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/12: 100%|██████████| 8419/8419 [42:34<00:00,  3.30it/s, batch_loss=0.0612]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/12 → Train Loss: 0.0730 | Val Loss: 0.0797\n→ Saved best model (val loss improved)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/12: 100%|██████████| 8419/8419 [42:29<00:00,  3.30it/s, batch_loss=0.0547]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/12 → Train Loss: 0.0691 | Val Loss: 0.0810\nVal loss không cải thiện (1/5)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/12: 100%|██████████| 8419/8419 [42:25<00:00,  3.31it/s, batch_loss=0.0651]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/12 → Train Loss: 0.0651 | Val Loss: 0.0812\nVal loss không cải thiện (2/5)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/12: 100%|██████████| 8419/8419 [42:26<00:00,  3.31it/s, batch_loss=0.0432]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/12 → Train Loss: 0.0613 | Val Loss: 0.0831\nVal loss không cải thiện (3/5)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/12:  26%|██▌       | 2159/8419 [10:53<31:34,  3.30it/s, batch_loss=0.053] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3610151879.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_roberta.pth'))\nmodel.eval()\n\nall_preds, all_targets = [], []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].cpu().numpy()\n        \n        outputs = model(input_ids, attention_mask).cpu().numpy()\n        all_preds.append(outputs)\n        all_targets.append(targets)\n\npreds = np.concatenate(all_preds)\ntargets = np.concatenate(all_targets)\n\ntraits = ['Ext', 'Neu', 'Agr', 'Con', 'Ope']\nfor i, trait in enumerate(traits):\n    rmse = np.sqrt(mean_squared_error(targets[:, i], preds[:, i]))\n    mae = mean_absolute_error(targets[:, i], preds[:, i])\n    r2 = r2_score(targets[:, i], preds[:, i])\n    print(f\"{trait}: RMSE = {rmse:.4f} | MAE = {mae:.4f} | R² = {r2:.4f}\")\n\noverall_rmse = np.sqrt(mean_squared_error(targets, preds))\noverall_r2 = r2_score(targets, preds, multioutput='uniform_average')\nprint(f\"\\nTổng thể: RMSE = {overall_rmse:.4f} | R² = {overall_r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T19:02:23.662044Z","iopub.execute_input":"2026-01-26T19:02:23.662694Z","iopub.status.idle":"2026-01-26T19:06:37.161561Z","shell.execute_reply.started":"2026-01-26T19:02:23.662656Z","shell.execute_reply":"2026-01-26T19:06:37.160773Z"}},"outputs":[{"name":"stdout","text":"Ext: RMSE = 0.2815 | MAE = 0.2284 | R² = 0.0941\nNeu: RMSE = 0.2958 | MAE = 0.2454 | R² = 0.0933\nAgr: RMSE = 0.2801 | MAE = 0.2281 | R² = 0.1306\nCon: RMSE = 0.2512 | MAE = 0.2027 | R² = 0.1003\nOpe: RMSE = 0.2965 | MAE = 0.2487 | R² = 0.0950\n\nTổng thể: RMSE = 0.2815 | R² = 0.1027\n","output_type":"stream"}],"execution_count":8}]}