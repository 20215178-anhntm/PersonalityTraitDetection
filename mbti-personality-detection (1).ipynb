{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4381,"sourceType":"datasetVersion","datasetId":2637,"isSourceIdPinned":false}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Machine Learning models\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import LinearSVC\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    classification_report,\n    confusion_matrix\n)\n# Evaluation\nfrom sklearn.metrics import (\n    accuracy_score,\n    classification_report,\n    confusion_matrix\n)\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:04.695152Z","iopub.execute_input":"2026-01-20T03:55:04.695391Z","iopub.status.idle":"2026-01-20T03:55:17.081293Z","shell.execute_reply.started":"2026-01-20T03:55:04.695365Z","shell.execute_reply":"2026-01-20T03:55:17.079964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install dependencies (run once)\n# pip install kagglehub[pandas-datasets]\n\nimport kagglehub\nfrom kagglehub import KaggleDatasetAdapter\n\n# Path to the file INSIDE the dataset\nfile_path = \"mbti_1.csv\"\n\n# Load the dataset\ndf = kagglehub.load_dataset(\n    KaggleDatasetAdapter.PANDAS,\n    \"datasnaek/mbti-type\",\n    file_path,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:17.083352Z","iopub.execute_input":"2026-01-20T03:55:17.084006Z","iopub.status.idle":"2026-01-20T03:55:19.122290Z","shell.execute_reply.started":"2026-01-20T03:55:17.083976Z","shell.execute_reply":"2026-01-20T03:55:19.121195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:19.123460Z","iopub.execute_input":"2026-01-20T03:55:19.123809Z","iopub.status.idle":"2026-01-20T03:55:19.306061Z","shell.execute_reply.started":"2026-01-20T03:55:19.123774Z","shell.execute_reply":"2026-01-20T03:55:19.305133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#showing the number of users per personality type\ndf.type.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:19.307303Z","iopub.execute_input":"2026-01-20T03:55:19.307581Z","iopub.status.idle":"2026-01-20T03:55:19.322336Z","shell.execute_reply.started":"2026-01-20T03:55:19.307548Z","shell.execute_reply":"2026-01-20T03:55:19.321288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#visualizing the number of users per personality type using a histogram\nplt.figure(figsize=(20,10))\nsns.countplot(df.type)\nplt.xlabel('Types count');","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:19.323531Z","iopub.execute_input":"2026-01-20T03:55:19.323793Z","iopub.status.idle":"2026-01-20T03:55:19.753409Z","shell.execute_reply.started":"2026-01-20T03:55:19.323770Z","shell.execute_reply":"2026-01-20T03:55:19.752544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#removing URLs and punctuation from dataset\n# 1. Replace '|||' with a space (mimics the split/join logic)\ndf['posts'] = df['posts'].str.replace(r'\\|\\|\\|', ' ', regex=True)\n\n# 2. Remove URLs\ndf['posts'] = df['posts'].str.replace(r\"http\\S+\", \"\", regex=True)\n\n# 3. Remove punctuation and numbers\ndf['posts'] = df['posts'].str.replace(r\"[-/@.?!_,:;()|0-9]\", \"\", regex=True)\n\n# 4. Remove extra whitespace (mimics the split('  ') logic but more robust)\ndf['posts'] = df['posts'].str.replace(r\"\\s+\", \" \", regex=True).str.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:19.754695Z","iopub.execute_input":"2026-01-20T03:55:19.755093Z","iopub.status.idle":"2026-01-20T03:55:25.029525Z","shell.execute_reply.started":"2026-01-20T03:55:19.755055Z","shell.execute_reply":"2026-01-20T03:55:25.028706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:25.037935Z","iopub.execute_input":"2026-01-20T03:55:25.038733Z","iopub.status.idle":"2026-01-20T03:55:25.050500Z","shell.execute_reply.started":"2026-01-20T03:55:25.038699Z","shell.execute_reply":"2026-01-20T03:55:25.049551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#identifying the different classes of users in the dataset\nlabels = df.type.unique()\nlabels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:25.051766Z","iopub.execute_input":"2026-01-20T03:55:25.052292Z","iopub.status.idle":"2026-01-20T03:55:25.072395Z","shell.execute_reply.started":"2026-01-20T03:55:25.052265Z","shell.execute_reply":"2026-01-20T03:55:25.071507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#mapping personality types with their numberical representation\nlabels2 = []\nlabel_rep = {}\nfor index,labels in enumerate(labels):\n    label_rep[labels] = index\n    labels2.append(labels)\nlabel_rep","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:25.073629Z","iopub.execute_input":"2026-01-20T03:55:25.073941Z","iopub.status.idle":"2026-01-20T03:55:25.090594Z","shell.execute_reply.started":"2026-01-20T03:55:25.073905Z","shell.execute_reply":"2026-01-20T03:55:25.089293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#replacing each personality type with its numerical representation\ndf['label'] = df.type.replace(label_rep)\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:25.092075Z","iopub.execute_input":"2026-01-20T03:55:25.092439Z","iopub.status.idle":"2026-01-20T03:55:25.126873Z","shell.execute_reply.started":"2026-01-20T03:55:25.092411Z","shell.execute_reply":"2026-01-20T03:55:25.125989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(\n    max_features=5000,\n    stop_words='english',\n    ngram_range=(1, 2),\n    min_df=5\n)\n\nX = tfidf.fit_transform(df['posts'])\ny = df['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:25.127932Z","iopub.execute_input":"2026-01-20T03:55:25.128228Z","iopub.status.idle":"2026-01-20T03:55:51.231531Z","shell.execute_reply.started":"2026-01-20T03:55:25.128203Z","shell.execute_reply":"2026-01-20T03:55:51.230496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:51.232667Z","iopub.execute_input":"2026-01-20T03:55:51.233030Z","iopub.status.idle":"2026-01-20T03:55:51.257746Z","shell.execute_reply.started":"2026-01-20T03:55:51.232972Z","shell.execute_reply":"2026-01-20T03:55:51.256608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\nsvm = LinearSVC(class_weight='balanced')\nsvm.fit(X_train, y_train)\n\ny_pred_svm = svm.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:51.259231Z","iopub.execute_input":"2026-01-20T03:55:51.259596Z","iopub.status.idle":"2026-01-20T03:55:56.187087Z","shell.execute_reply.started":"2026-01-20T03:55:51.259568Z","shell.execute_reply":"2026-01-20T03:55:56.186109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy\nacc = accuracy_score(y_test, y_pred_svm)\n\n# Macro-averaged metrics (recommended for imbalanced MBTI data)\nprecision_macro = precision_score(y_test, y_pred_svm, average=\"macro\")\nrecall_macro = recall_score(y_test, y_pred_svm, average=\"macro\")\nf1_macro = f1_score(y_test, y_pred_svm, average=\"macro\")\n\nprint(\"SVM Performance\")\nprint(\"------------------------------\")\nprint(f\"Accuracy        : {acc:.4f}\")\nprint(f\"Macro Precision : {precision_macro:.4f}\")\nprint(f\"Macro Recall    : {recall_macro:.4f}\")\nprint(f\"Macro F1-score  : {f1_macro:.4f}\")\n\nprint(\"\\nSVM Classification Report\")\nprint(\"------------------------------\")\nprint(classification_report(y_test, y_pred_svm))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm_svm = confusion_matrix(y_test, y_pred_svm)\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    cm_svm,\n    annot=True,\n    fmt=\"d\",\n    cmap=\"Blues\",\n    cbar=False\n)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix — SVM\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX_train_dense = X_train.toarray()\nX_test_dense = X_test.toarray()\n\nrf = RandomForestClassifier(\n    n_estimators=200,\n    class_weight='balanced',\n    random_state=42,\n    n_jobs=-1\n)\n\nrf.fit(X_train_dense, y_train)\ny_pred_rf = rf.predict(X_test_dense)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:55:56.188558Z","iopub.execute_input":"2026-01-20T03:55:56.189198Z","iopub.status.idle":"2026-01-20T03:56:22.890765Z","shell.execute_reply.started":"2026-01-20T03:55:56.189169Z","shell.execute_reply":"2026-01-20T03:56:22.889431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_rf = accuracy_score(y_test, y_pred_rf)\nprecision_rf = precision_score(y_test, y_pred_rf, average=\"macro\")\nrecall_rf = recall_score(y_test, y_pred_rf, average=\"macro\")\nf1_rf = f1_score(y_test, y_pred_rf, average=\"macro\")\n\nprint(\"Random Forest Performance\")\nprint(\"------------------------------\")\nprint(f\"Accuracy        : {acc_rf:.4f}\")\nprint(f\"Macro Precision : {precision_rf:.4f}\")\nprint(f\"Macro Recall    : {recall_rf:.4f}\")\nprint(f\"Macro F1-score  : {f1_rf:.4f}\")\n\nprint(\"\\nRandom Forest Classification Report\")\nprint(\"------------------------------\")\nprint(classification_report(y_test, y_pred_rf))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_rf)\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    cmap=\"Blues\",\n    cbar=False\n)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix — Random Forest\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:56:22.892099Z","iopub.execute_input":"2026-01-20T03:56:22.892391Z","iopub.status.idle":"2026-01-20T03:56:23.498623Z","shell.execute_reply.started":"2026-01-20T03:56:22.892363Z","shell.execute_reply":"2026-01-20T03:56:23.497500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\nsample_weight = compute_sample_weight(\n    class_weight=\"balanced\",\n    y=y_train\n)\n\nxgb_model = xgb.XGBClassifier(\n    objective='multi:softmax',\n    num_class=16,\n    n_estimators=300,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    eval_metric='mlogloss',\n    n_jobs=-1,\n    random_state=42,\n)\n\nxgb_model.fit(\n    X_train,\n    y_train,\n    sample_weight=sample_weight\n)\n\ny_pred_xgb = xgb_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T03:56:23.500178Z","iopub.execute_input":"2026-01-20T03:56:23.500486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_xgb = accuracy_score(y_test, y_pred_xgb)\nprecision_xgb = precision_score(y_test, y_pred_xgb, average=\"macro\")\nrecall_xgb = recall_score(y_test, y_pred_xgb, average=\"macro\")\nf1_xgb = f1_score(y_test, y_pred_xgb, average=\"macro\")\n\nprint(\"XGBoost Performance\")\nprint(\"------------------------------\")\nprint(f\"Accuracy        : {acc_xgb:.4f}\")\nprint(f\"Macro Precision : {precision_xgb:.4f}\")\nprint(f\"Macro Recall    : {recall_xgb:.4f}\")\nprint(f\"Macro F1-score  : {f1_xgb:.4f}\")\n\nprint(\"\\nXGBoost Classification Report\")\nprint(\"------------------------------\")\nprint(classification_report(y_test, y_pred_xgb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm_xgb = confusion_matrix(y_test, y_pred_xgb)\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    cm_xgb,\n    annot=True,\n    fmt=\"d\",\n    cmap=\"Blues\",\n    cbar=False\n)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix — XGBoost\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\n\nlgb_model = lgb.LGBMClassifier(\n    objective='multiclass',\n    num_class=16,\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=-1,\n    class_weight='balanced',\n    n_jobs=-1,\n    verbosity=-1,\n)\n\nlgb_model.fit(X_train, y_train)\ny_pred_lgb = lgb_model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_lgb = accuracy_score(y_test, y_pred_lgb)\nprecision_lgb = precision_score(y_test, y_pred_lgb, average=\"macro\")\nrecall_lgb = recall_score(y_test, y_pred_lgb, average=\"macro\")\nf1_lgb = f1_score(y_test, y_pred_lgb, average=\"macro\")\n\nprint(\"LightGBM Performance\")\nprint(\"------------------------------\")\nprint(f\"Accuracy        : {acc_lgb:.4f}\")\nprint(f\"Macro Precision : {precision_lgb:.4f}\")\nprint(f\"Macro Recall    : {recall_lgb:.4f}\")\nprint(f\"Macro F1-score  : {f1_lgb:.4f}\")\n\nprint(\"\\nLightGBM Classification Report\")\nprint(\"------------------------------\")\nprint(classification_report(y_test, y_pred_lgb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm_lgb = confusion_matrix(y_test, y_pred_lgb)\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    cm_lgb,\n    annot=True,\n    fmt=\"d\",\n    cmap=\"Blues\",\n    cbar=False\n)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix — LightGBM\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sentence-transformers scikit-learn xgboost lightgbm\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nimport lightgbm as lgb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers torch scikit-learn pandas\nimport torch\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n\nmodel.eval()  # inference mode","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bert_base_encode(texts, tokenizer, model, max_length=512):\n    embeddings = []\n\n    with torch.no_grad():\n        for text in texts:\n            inputs = tokenizer(\n                text,\n                return_tensors=\"pt\",\n                truncation=True,\n                padding=\"max_length\",\n                max_length=max_length\n            )\n\n            outputs = model(**inputs)\n            cls_embedding = outputs.last_hidden_state[:, 0, :]  # (1, 768)\n            embeddings.append(cls_embedding.squeeze().numpy())\n\n    return np.vstack(embeddings)\nX = bert_base_encode(\n    df['posts'].tolist(),\n    tokenizer,\n    model\n)\n\ny = df['label'].values\n\nprint(X.shape, y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_cols = [f\"bert_{i}\" for i in range(X.shape[1])]\n\ndf_bert = pd.DataFrame(X, columns=embedding_cols)\ndf_bert[\"label\"] = y\n\ndf_bert.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,        # 80% train, 20% test\n    random_state=42,\n    stratify=y            # giữ tỷ lệ class\n)\n\nprint(\"X_train:\", X_train.shape)\nprint(\"X_test :\", X_test.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"y_test :\", y_test.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf = RandomForestClassifier(\n    n_estimators=500,\n    n_jobs=-1,\n    random_state=42,\n    class_weight=\"balanced\",\n)\n\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nprint(\"RF (balanced) Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, classification_report\n\nnum_classes = len(np.unique(y_train))\n\nlgb_model = lgb.LGBMClassifier(\n    n_estimators=600,\n    learning_rate=0.05,\n    num_leaves=63,\n    objective=\"multiclass\",\n    num_class=num_classes,\n    class_weight=\"balanced\",  \n    random_state=42,\n    n_jobs=-1,\n    verbosity=-1,\n)\n\nlgb_model.fit(X_train, y_train)\n\ny_pred_lgb = lgb_model.predict(X_test)\n\nprint(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred_lgb))\nprint(classification_report(y_test, y_pred_lgb, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 5. XGBoost (with sample weights)\n# =========================\nnum_classes = len(np.unique(y_train))\n\nsample_weight = compute_sample_weight(\n    class_weight=\"balanced\",\n    y=y_train\n)\n\nxgb_model = xgb.XGBClassifier(\n    n_estimators=600,\n    max_depth=8,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective=\"multi:softprob\",\n    num_class=num_classes,\n    eval_metric=\"mlogloss\",\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb_model.fit(\n    X_train,\n    y_train,\n    sample_weight=sample_weight\n)\n\ny_pred_xgb = np.argmax(\n    xgb_model.predict_proba(X_test),\n    axis=1\n)\n\nprint(\"\\n===== XGBoost =====\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\nprint(classification_report(y_test, y_pred_xgb, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_model = LinearSVC(\n    class_weight=\"balanced\",  \n    random_state=42,\n    max_iter=10000\n)\n\nsvm_model.fit(X_train, y_train)\n\ny_pred_svm = svm_model.predict(X_test)\n\nprint(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\nprint(classification_report(y_test, y_pred_svm, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Sentence-BERT model\nbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# Encode posts into vectors\nX = bert_model.encode(\n    df['posts'].tolist(),\n    batch_size=32,\n    show_progress_bar=True\n)\n\n# Labels\ny = df['label'].values\n\nprint(X.shape, y.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    random_state=42,\n    stratify=y\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf = RandomForestClassifier(\n    n_estimators=500,\n    n_jobs=-1,\n    random_state=42,\n    class_weight=\"balanced\"  \n)\n\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nprint(\"RF (balanced) Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\n\nnum_classes = len(np.unique(y_train))\n\nxgb_model = xgb.XGBClassifier(\n    n_estimators=600,\n    max_depth=8,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective=\"multi:softprob\",\n    num_class=num_classes,\n    eval_metric=\"mlogloss\",\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb_model.fit(\n    X_train,\n    y_train,\n    sample_weight=sample_weight\n)\n\ny_pred_xgb = np.argmax(\n    xgb_model.predict_proba(X_test),\n    axis=1\n)\n\nprint(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\nprint(classification_report(y_test, y_pred_xgb, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, classification_report\n\nnum_classes = len(np.unique(y_train))\n\nlgb_model = lgb.LGBMClassifier(\n    n_estimators=600,\n    learning_rate=0.05,\n    num_leaves=63,\n    objective=\"multiclass\",\n    num_class=num_classes,\n    class_weight=\"balanced\",  \n    random_state=42,\n    n_jobs=-1\n)\n\nlgb_model.fit(X_train, y_train)\n\ny_pred_lgb = lgb_model.predict(X_test)\n\nprint(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred_lgb))\nprint(classification_report(y_test, y_pred_lgb, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_model = LinearSVC(\n    class_weight=\"balanced\",  \n    random_state=42,\n    max_iter=10000\n)\n\nsvm_model.fit(X_train, y_train)\n\ny_pred_svm = svm_model.predict(X_test)\n\nprint(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\nprint(classification_report(y_test, y_pred_svm, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}